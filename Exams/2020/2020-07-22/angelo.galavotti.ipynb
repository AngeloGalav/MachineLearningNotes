{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>class_x</th>\n",
       "      <th>B</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>class_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.386248</td>\n",
       "      <td>1.536628</td>\n",
       "      <td>1.232589</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.432057</td>\n",
       "      <td>1.039420</td>\n",
       "      <td>0.280469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.686649</td>\n",
       "      <td>4.640702</td>\n",
       "      <td>0.823433</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.036329</td>\n",
       "      <td>0.526320</td>\n",
       "      <td>-0.419013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.474124</td>\n",
       "      <td>1.576616</td>\n",
       "      <td>-1.256234</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179770</td>\n",
       "      <td>0.157974</td>\n",
       "      <td>-0.162869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.343790</td>\n",
       "      <td>-0.514008</td>\n",
       "      <td>1.520392</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.299109</td>\n",
       "      <td>-0.152250</td>\n",
       "      <td>0.045123</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.187600</td>\n",
       "      <td>0.289041</td>\n",
       "      <td>1.318321</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.089699</td>\n",
       "      <td>-0.494995</td>\n",
       "      <td>-0.661858</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         C         E  class_x         B         D         F  \\\n",
       "Index                                                                        \n",
       "0     -0.386248  1.536628  1.232589        1 -1.432057  1.039420  0.280469   \n",
       "1     -2.686649  4.640702  0.823433        1 -4.036329  0.526320 -0.419013   \n",
       "2      0.474124  1.576616 -1.256234        0  0.179770  0.157974 -0.162869   \n",
       "3     -1.343790 -0.514008  1.520392        2 -1.299109 -0.152250  0.045123   \n",
       "4     -2.187600  0.289041  1.318321        2 -2.089699 -0.494995 -0.661858   \n",
       "\n",
       "       class_y  \n",
       "Index           \n",
       "0            1  \n",
       "1            1  \n",
       "2            0  \n",
       "3            2  \n",
       "4            2  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('exam_1.csv')\n",
    "df2 = pd.read_csv('exam_2.csv')\n",
    "\n",
    "df1['class_x'] = df1['class']\n",
    "df1 = df1.drop(labels=['class'], axis=1)\n",
    "\n",
    "df1.head()\n",
    "df2['class_y'] = df2['class']\n",
    "df2 = df2.drop('class', axis=1)\n",
    "\n",
    "df = pd.merge(df1, df2)\n",
    "df.rename(columns={'Unnamed: 0':\"Index\"}, inplace=True)\n",
    "df.set_index('Index', inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>class</th>\n",
       "      <th>B</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.386248</td>\n",
       "      <td>1.536628</td>\n",
       "      <td>1.232589</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.432057</td>\n",
       "      <td>1.039420</td>\n",
       "      <td>0.280469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.686649</td>\n",
       "      <td>4.640702</td>\n",
       "      <td>0.823433</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.036329</td>\n",
       "      <td>0.526320</td>\n",
       "      <td>-0.419013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.474124</td>\n",
       "      <td>1.576616</td>\n",
       "      <td>-1.256234</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179770</td>\n",
       "      <td>0.157974</td>\n",
       "      <td>-0.162869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.343790</td>\n",
       "      <td>-0.514008</td>\n",
       "      <td>1.520392</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.299109</td>\n",
       "      <td>-0.152250</td>\n",
       "      <td>0.045123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.187600</td>\n",
       "      <td>0.289041</td>\n",
       "      <td>1.318321</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.089699</td>\n",
       "      <td>-0.494995</td>\n",
       "      <td>-0.661858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         C         E  class         B         D         F\n",
       "Index                                                                   \n",
       "0     -0.386248  1.536628  1.232589      1 -1.432057  1.039420  0.280469\n",
       "1     -2.686649  4.640702  0.823433      1 -4.036329  0.526320 -0.419013\n",
       "2      0.474124  1.576616 -1.256234      0  0.179770  0.157974 -0.162869\n",
       "3     -1.343790 -0.514008  1.520392      2 -1.299109 -0.152250  0.045123\n",
       "4     -2.187600  0.289041  1.318321      2 -2.089699 -0.494995 -0.661858"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df[df['class_x'] != df['class_y']]))\n",
    "\n",
    "df0 = df[df['class_x'] == df['class_y']]\n",
    "\n",
    "print(len(df0[df0['class_x'] != df0['class_y']]))\n",
    "\n",
    "df0 = df0.drop(columns=['class_y'])\n",
    "df0 = df0.rename(columns={'class_x':'class'})\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the final dataset is (1984, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.386248</td>\n",
       "      <td>-1.432057</td>\n",
       "      <td>1.536628</td>\n",
       "      <td>1.039420</td>\n",
       "      <td>1.232589</td>\n",
       "      <td>0.280469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.686649</td>\n",
       "      <td>-4.036329</td>\n",
       "      <td>4.640702</td>\n",
       "      <td>0.526320</td>\n",
       "      <td>0.823433</td>\n",
       "      <td>-0.419013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.474124</td>\n",
       "      <td>0.179770</td>\n",
       "      <td>1.576616</td>\n",
       "      <td>0.157974</td>\n",
       "      <td>-1.256234</td>\n",
       "      <td>-0.162869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.343790</td>\n",
       "      <td>-1.299109</td>\n",
       "      <td>-0.514008</td>\n",
       "      <td>-0.152250</td>\n",
       "      <td>1.520392</td>\n",
       "      <td>0.045123</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.187600</td>\n",
       "      <td>-2.089699</td>\n",
       "      <td>0.289041</td>\n",
       "      <td>-0.494995</td>\n",
       "      <td>1.318321</td>\n",
       "      <td>-0.661858</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B         C         D         E         F  class\n",
       "Index                                                                   \n",
       "0     -0.386248 -1.432057  1.536628  1.039420  1.232589  0.280469      1\n",
       "1     -2.686649 -4.036329  4.640702  0.526320  0.823433 -0.419013      1\n",
       "2      0.474124  0.179770  1.576616  0.157974 -1.256234 -0.162869      0\n",
       "3     -1.343790 -1.299109 -0.514008 -0.152250  1.520392  0.045123      2\n",
       "4     -2.187600 -2.089699  0.289041 -0.494995  1.318321 -0.661858      2"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df0.reindex(sorted(df0.columns), axis=1)\n",
    "\n",
    "print(\"Size of the final dataset is {}\".format(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "# Neural network\n",
    "# KNearnest \n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_lbls = [\n",
    "              'dt', \n",
    "              'lp', \n",
    "             'knn',\n",
    "            ]\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_param_dt = [{'max_depth': [*range(1,20)]}]\n",
    "tuned_param_lp = [{'early_stopping': [True]}]\n",
    "tuned_param_knn =[{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "\n",
    "models = {\n",
    "    'dt': {'name': 'Decision Tree       ',\n",
    "           'estimator': DecisionTreeClassifier(), \n",
    "           'param': tuned_param_dt,\n",
    "          },\n",
    "    'lp': {'name': 'Linear Perceptron   ',\n",
    "           'estimator': Perceptron(),\n",
    "           'param': tuned_param_lp,\n",
    "          },\n",
    "    'knn':{'name': 'K Nearest Neighbor ',\n",
    "           'estimator': KNeighborsClassifier(),\n",
    "           'param': tuned_param_knn\n",
    "       },\n",
    "}\n",
    "\n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the single models, without hyperparameter tuning, first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1388 samples\n",
      "Accuracy score for Decision Tree        is 0.8104026845637584\n",
      "Accuracy score for Linear Perceptron    is 0.7214765100671141\n",
      "Accuracy score for K Nearest Neighbor  is 0.8590604026845637\n",
      "The best model by accuracy is K Nearest Neighbor \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X = df.drop(columns='class')\n",
    "y = df['class']\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=0.7)\n",
    "print(\"Training on {:} samples\".format(Xtrain.shape[0]))\n",
    "\n",
    "accuracy_scores = {} \n",
    "\n",
    "for model in model_lbls:\n",
    "    estimator = models[model]['estimator']\n",
    "    estimator.fit(Xtrain, ytrain)\n",
    "    y_pred = estimator.predict(Xtest)\n",
    "    accuracy_scores[model] = accuracy_score(ytest, y_pred)\n",
    "    print(\"Accuracy score for {} is {}\".format(models[model]['name'], accuracy_scores[model])) # Basing only on accuracy\n",
    "\n",
    "print(\"The best model by accuracy is {}\".format(models[max(accuracy_scores, key=accuracy_scores.get)]['name'])) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function allows us to better understand which model/parameter combination is better for the task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model): # Note: could have put the train part here also...\n",
    "    print(\"Best parameters set found on train set:\")\n",
    "    print()\n",
    "    # if best is linear there is no gamma parameter\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on train set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    params = model.cv_results_['params']\n",
    "    for mean, std, params_tuple in zip(means, stds, params):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params_tuple))\n",
    "    print()\n",
    "    print(\"Detailed classification report for the best parameter set:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full train set.\")\n",
    "    print(\"The scores are computed on the full test set.\")\n",
    "    print()\n",
    "    y_true, y_pred = ytest, model.predict(Xtest)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tune the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Trying model Decision Tree       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'max_depth': 5}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.428 (+/-0.019) for {'max_depth': 1}\n",
      "0.821 (+/-0.032) for {'max_depth': 2}\n",
      "0.825 (+/-0.033) for {'max_depth': 3}\n",
      "0.826 (+/-0.052) for {'max_depth': 4}\n",
      "0.834 (+/-0.050) for {'max_depth': 5}\n",
      "0.825 (+/-0.052) for {'max_depth': 6}\n",
      "0.834 (+/-0.053) for {'max_depth': 7}\n",
      "0.830 (+/-0.031) for {'max_depth': 8}\n",
      "0.833 (+/-0.039) for {'max_depth': 9}\n",
      "0.823 (+/-0.019) for {'max_depth': 10}\n",
      "0.830 (+/-0.034) for {'max_depth': 11}\n",
      "0.833 (+/-0.030) for {'max_depth': 12}\n",
      "0.826 (+/-0.036) for {'max_depth': 13}\n",
      "0.834 (+/-0.015) for {'max_depth': 14}\n",
      "0.830 (+/-0.022) for {'max_depth': 15}\n",
      "0.828 (+/-0.046) for {'max_depth': 16}\n",
      "0.830 (+/-0.028) for {'max_depth': 17}\n",
      "0.826 (+/-0.032) for {'max_depth': 18}\n",
      "0.829 (+/-0.027) for {'max_depth': 19}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79       204\n",
      "           1       0.73      0.90      0.81       173\n",
      "           2       0.92      0.84      0.88       219\n",
      "\n",
      "    accuracy                           0.83       596\n",
      "   macro avg       0.83      0.83      0.82       596\n",
      "weighted avg       0.83      0.83      0.83       596\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Linear Perceptron   \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'early_stopping': True}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.762 (+/-0.056) for {'early_stopping': True}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74       204\n",
      "           1       0.77      0.76      0.76       173\n",
      "           2       0.78      0.79      0.78       219\n",
      "\n",
      "    accuracy                           0.76       596\n",
      "   macro avg       0.76      0.76      0.76       596\n",
      "weighted avg       0.76      0.76      0.76       596\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model K Nearest Neighbor \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'n_neighbors': 7}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.822 (+/-0.014) for {'n_neighbors': 1}\n",
      "0.812 (+/-0.019) for {'n_neighbors': 2}\n",
      "0.837 (+/-0.033) for {'n_neighbors': 3}\n",
      "0.845 (+/-0.047) for {'n_neighbors': 4}\n",
      "0.844 (+/-0.043) for {'n_neighbors': 5}\n",
      "0.845 (+/-0.038) for {'n_neighbors': 6}\n",
      "0.848 (+/-0.043) for {'n_neighbors': 7}\n",
      "0.844 (+/-0.040) for {'n_neighbors': 8}\n",
      "0.846 (+/-0.042) for {'n_neighbors': 9}\n",
      "0.844 (+/-0.036) for {'n_neighbors': 10}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83       204\n",
      "           1       0.79      0.87      0.83       173\n",
      "           2       0.89      0.92      0.91       219\n",
      "\n",
      "    accuracy                           0.86       596\n",
      "   macro avg       0.86      0.86      0.85       596\n",
      "weighted avg       0.86      0.86      0.86       596\n",
      "\n",
      "\n",
      "Summary of results for precision\n",
      "Estimator\n",
      "Decision Tree       \t - score: 0.83%\n",
      "Linear Perceptron   \t - score: 0.76%\n",
      "K Nearest Neighbor \t - score: 0.85%\n",
      "----------------------------------------\n",
      "Trying model Decision Tree       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'max_depth': 8}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.582 (+/-0.018) for {'max_depth': 1}\n",
      "0.815 (+/-0.038) for {'max_depth': 2}\n",
      "0.820 (+/-0.038) for {'max_depth': 3}\n",
      "0.818 (+/-0.044) for {'max_depth': 4}\n",
      "0.830 (+/-0.044) for {'max_depth': 5}\n",
      "0.830 (+/-0.055) for {'max_depth': 6}\n",
      "0.832 (+/-0.046) for {'max_depth': 7}\n",
      "0.834 (+/-0.039) for {'max_depth': 8}\n",
      "0.825 (+/-0.036) for {'max_depth': 9}\n",
      "0.825 (+/-0.033) for {'max_depth': 10}\n",
      "0.829 (+/-0.031) for {'max_depth': 11}\n",
      "0.825 (+/-0.025) for {'max_depth': 12}\n",
      "0.828 (+/-0.025) for {'max_depth': 13}\n",
      "0.829 (+/-0.021) for {'max_depth': 14}\n",
      "0.829 (+/-0.023) for {'max_depth': 15}\n",
      "0.820 (+/-0.026) for {'max_depth': 16}\n",
      "0.820 (+/-0.031) for {'max_depth': 17}\n",
      "0.831 (+/-0.037) for {'max_depth': 18}\n",
      "0.832 (+/-0.034) for {'max_depth': 19}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       204\n",
      "           1       0.78      0.82      0.80       173\n",
      "           2       0.88      0.86      0.87       219\n",
      "\n",
      "    accuracy                           0.83       596\n",
      "   macro avg       0.83      0.83      0.83       596\n",
      "weighted avg       0.83      0.83      0.83       596\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Linear Perceptron   \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'early_stopping': True}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.749 (+/-0.060) for {'early_stopping': True}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74       204\n",
      "           1       0.77      0.76      0.76       173\n",
      "           2       0.78      0.79      0.78       219\n",
      "\n",
      "    accuracy                           0.76       596\n",
      "   macro avg       0.76      0.76      0.76       596\n",
      "weighted avg       0.76      0.76      0.76       596\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model K Nearest Neighbor \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'n_neighbors': 7}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.821 (+/-0.014) for {'n_neighbors': 1}\n",
      "0.801 (+/-0.021) for {'n_neighbors': 2}\n",
      "0.835 (+/-0.035) for {'n_neighbors': 3}\n",
      "0.842 (+/-0.050) for {'n_neighbors': 4}\n",
      "0.843 (+/-0.044) for {'n_neighbors': 5}\n",
      "0.843 (+/-0.038) for {'n_neighbors': 6}\n",
      "0.847 (+/-0.045) for {'n_neighbors': 7}\n",
      "0.844 (+/-0.043) for {'n_neighbors': 8}\n",
      "0.846 (+/-0.045) for {'n_neighbors': 9}\n",
      "0.844 (+/-0.038) for {'n_neighbors': 10}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83       204\n",
      "           1       0.79      0.87      0.83       173\n",
      "           2       0.89      0.92      0.91       219\n",
      "\n",
      "    accuracy                           0.86       596\n",
      "   macro avg       0.86      0.86      0.85       596\n",
      "weighted avg       0.86      0.86      0.86       596\n",
      "\n",
      "\n",
      "Summary of results for recall\n",
      "Estimator\n",
      "Decision Tree       \t - score: 0.83%\n",
      "Linear Perceptron   \t - score: 0.75%\n",
      "K Nearest Neighbor \t - score: 0.85%\n"
     ]
    }
   ],
   "source": [
    "best_scores = {} \n",
    "\n",
    "for score in scores:\n",
    "    for model in model_lbls: # model labels\n",
    "        \n",
    "        print('-'*40)\n",
    "        print(\"Trying model {}\".format(models[model]['name']))\n",
    "    \n",
    "        estimator = GridSearchCV(scoring='%s_macro' % score, n_jobs=2, cv=5, # '%s_macro' to format to actual scikit_learn param (accuracy_macro)\n",
    "            estimator=models[model]['estimator'], param_grid=models[model]['param']) # n_job for multicore cv, param_grids is the \n",
    "                                                                                    # list of params to try as values\n",
    "        estimator.fit(Xtrain, ytrain) # this step must be done, or else no best score\n",
    "        \n",
    "        print_results(estimator)\n",
    "        best_scores[model] = estimator.best_score_\n",
    "\n",
    "\n",
    "    print(\"Summary of results for {}\".format(score)) # copy pasted from official solution since i hate printing stuff :|\n",
    "    print(\"Estimator\")\n",
    "    for m in best_scores.keys():\n",
    "        print(\"{}\\t - score: {:4.2}%\".format(models[m]['name'], best_scores[m]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now instantiating the models using the best parameters found so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=7)\n",
    "lp = Perceptron(early_stopping=True)\n",
    "knn = KNeighborsClassifier(n_neighbors=7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each classification method, compute the _accuracy_ and the _confusion matrix_ on the test set\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of DT: \n",
      "[[164  25  15]\n",
      " [ 22 139  12]\n",
      " [ 12  18 189]]\n",
      "Confusion matrix of LP: \n",
      "[[152  34  18]\n",
      " [ 11 131  31]\n",
      " [ 42   5 172]]\n",
      "Confusion matrix of KNN: \n",
      "[[159  29  16]\n",
      " [ 14 151   8]\n",
      " [  6  12 201]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "accuracy_scores = [] \n",
    "\n",
    "dt.fit(Xtrain, ytrain)\n",
    "y_pred = dt.predict(Xtest)\n",
    "accuracy_scores.append(accuracy_score(ytest, y_pred))\n",
    "\n",
    "conf_dt = confusion_matrix(ytest, y_pred)\n",
    "print(\"Confusion matrix of DT: \")\n",
    "print(conf_dt)\n",
    "\n",
    "lp.fit(Xtrain, ytrain)\n",
    "y_pred = lp.predict(Xtest)\n",
    "accuracy_scores.append(accuracy_score(ytest, y_pred))\n",
    "\n",
    "conf_lp = confusion_matrix(ytest, y_pred) \n",
    "print(\"Confusion matrix of LP: \")\n",
    "print(conf_lp)\n",
    "\n",
    "knn.fit(Xtrain, ytrain)\n",
    "y_pred = knn.predict(Xtest)\n",
    "accuracy_scores.append(accuracy_score(ytest, y_pred))\n",
    "\n",
    "conf_knn = confusion_matrix(ytest, y_pred)\n",
    "print(\"Confusion matrix of KNN: \")\n",
    "print(conf_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "classfier_names = ['Decision Tree', 'Linear Perceptron', 'K Nearest Neighbors']\n",
    "plt.title('Accuracies of tested methods')\n",
    "plt.bar(classfier_names, accuracy_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b18a9988e9255073277d135c7087261722b40fca21f654d051abd907f565cc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
