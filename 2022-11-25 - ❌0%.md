## Frequent Itemset Generation
Given D items, there are $M = 2^D$ possible candidate itemsets.
The idea is to _reduce_ the _number of candidates_ $M$, by using pruning techniques. 
Or, we can reduce the number of comparisons $NM$.

#### Reducing Number of Candidates
__Apriori principle__: if an _itemset is frequent_, then _all of its subsets_ must also be _frequent_.
![[a_priori_principle.png]]
This means that the _support of an itemset_ never exceeds _the support of its subsets_. 

